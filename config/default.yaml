# Default Configuration for 3D Bin Packing with TAP-Net
# Paper Reference: "A deep reinforcement learning approach for the 3D bin packing problem"

# Environment Configuration
environment:
  container_size: [10.0, 10.0, 10.0]  # Container dimensions [L, W, H]
  grid_size: 10                        # Height map resolution
  max_items: 50                        # Maximum items per episode
  item_size_range: [0.1, 0.5]         # Item size as fraction of container
  enable_action_mask: true             # Use heuristic action masking
  reward_type: "hybrid"                # Reward function: hybrid, utilization, dense
  normalize_state: true                # Normalize state features

# Model Architecture Configuration
model:
  d_model: 256                # Transformer hidden dimension
  nhead: 8                    # Number of attention heads
  num_layers: 4               # Number of Transformer layers
  dim_feedforward: 1024       # Feed-forward network dimension
  dropout: 0.1                # Dropout rate
  share_encoder: false        # Share encoders between actor/critic

# Training Configuration (PPO)
training:
  # Total training
  total_timesteps: 1_000_000  # Total environment steps

  # Rollout
  buffer_size: 2048           # Number of steps to collect per update

  # PPO hyperparameters (from paper)
  learning_rate: 0.0003       # Initial learning rate
  gamma: 0.99                 # Discount factor
  gae_lambda: 0.95            # GAE lambda parameter
  clip_epsilon: 0.2           # PPO clip parameter
  value_coef: 0.5             # Value loss coefficient
  entropy_coef: 0.01          # Entropy bonus coefficient
  max_grad_norm: 0.5          # Gradient clipping threshold

  # Update settings
  n_epochs: 10                # Epochs per update
  batch_size: 256             # Minibatch size

  # Learning rate schedule
  lr_schedule: "step"         # Options: step, linear, cosine
  lr_step_size: 100           # Steps between LR decay
  lr_gamma: 0.95              # LR decay factor

  # Device
  device: "cuda"              # Device: cuda, cpu, mps

# Checkpoint Configuration
checkpoint:
  save_frequency: 100         # Save every N updates
  eval_frequency: 10          # Evaluate every N updates
  keep_best_n: 5              # Keep best N checkpoints
  checkpoint_dir: "checkpoints"
  auto_resume: true           # Automatically resume from latest checkpoint

# Logging Configuration
logging:
  log_dir: "logs"
  log_frequency: 1            # Log every N updates
  eval_episodes: 5            # Number of episodes for evaluation

# Experiment Configuration
experiment:
  name: "tap_net_default"
  seed: 42
  notes: "Default TAP-Net configuration from paper"
